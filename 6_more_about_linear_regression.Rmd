---
title: "Untitled"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Подробнее о линейной регрессии

Есть куча методов

![Классификация методов статистического вывода](img/table.png)

Но оказывается всё можно свести к тому или иному выводу регрессионого анализа.

Регрессия это очень важный пункт. От него потом легче понимать машинное обучение.

### Ограничения 

![_](img/ogran.PNG)

* Линейность взаимосвязи ЗП и НП

Рассмотрим пример:

```{r}
library(tidyverse)
data(mtcars)
ggplot(mtcars, aes(hp, mpg)) + geom_point()
```

Мы можем записать уравнение линейной регрессии $mpg = b_0 + b_1 hp$

```{r}
ggplot(mtcars, aes(hp, mpg)) + geom_point() + geom_smooth(method = "lm")
```

Но и на графике, и по ошибкам на прямой выше, видно, что связь скорее всего не линейная

Поэтому в подобных случаях линейная регрессия не лучшее решение. Особенно, если мы хотим предсказывать значения.

Как бороться? Лучше сразу строить данные. Есть способы --- можно модифицировать зависимость.

### Трансформация Тьюки

Основная идея --- трансформировать независимую переменную (предиктор), чтобы  ликвидировать нелинейность связи. Возведением в степень.

Нюанс, если показатель степени $\lambda$ ниже нуля, то будем подставлять минус, чтобы перевернуть

![Классификация методов статистического вывода](img/tyki.png)

Давайте реализуем несколько преобразований

```{r}
ggplot(mtcars, aes(hp^0.5, mpg)) + geom_point()
ggplot(mtcars, aes(hp^-0.5, mpg)) + geom_point()
ggplot(mtcars, aes(-hp^-0.5, mpg)) + geom_point()
```

### Логарифмическая трансформация переменных

Что будет, если мы применим логарифмирование одновременно и к зависимой переменной и к независимой

```{r}
qplot(data = mtcars, x = log(hp), y = log(mpg))
```

На самом деле мы вроде как справились с нелинейностью взаимосвязи.

Создадим 

```{r}
fit3 <- lm(log(mpg)~log(hp), mtcars)
summary(fit3)
```

Что говорит коэффициент при log(hp) --- у нас при единичном изменении log(hp) значение log(mpg) будет уменьшаться на приблизительно 0.5. 
Можно перейти от оценки логарифмов к обычным значениям.

Вспмомним мат.основы регрессии. Если порядок иксов будет изменяться на единицу, то изменение предсказаний будет равно коэффициенту при иксах:

![_](img/coef_pri_iks.PNG)

Что теперь? у нас исходная модель изменилась. У нас теперь логарифмы.

Теперь у нас коэффициент бэ один показывает на сколько процентов увеличится исходной переменной предиктор изменится на один процент

![_](img/dokaz.PNG)

Т.е. как пример разберём вот такую ситуацию:

![_](img/primer.PNG)

#### Вывод

Когда используем трансформацию и зависмой и независимой переменной, мы говорим, что коэффициент при логарифме икс это то на сколько процентов увеличится зависимой переменной, при условии что значение независимой переменной увеличится на один процент.

Т.е. в случае модели fit3 --- при единичном увеличении лошадинных сил на один  процент  значение расхода топлива уменьшита на пол.процента (-0.53009)

Т.е. если посмотреть на график рассеяния нелогарифмированных величин, то там видно что при нам такая трактовка и говорит что связь не линейна. Потому что чем дальше от исходного значения тем шире нужно сделать шажок для того чтобы было справедливо высказывание об угасании на пол.процента

Говоря об остальных трансформациях предикторов или зависимой переменной

![_](img/interpretation.PNG)