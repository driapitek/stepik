---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Анализ номинативных данных

## Постановка задачи

Здесь будем рассматривать случаи, когда основной герой --- номинативная переменная


### Проверка гипотезы о распределении номинативной переменной

1. Хотим проверить гипотезу о том, что распределение некоторой номинативной переменной отличается от заданной.

Предположим, какая партия является фаворитом.

Гипотеза --- наше империческое распределение частот, отличается от заданного теоретического.

Нулевая гипотеза --- все три партии встречаются равновероятно. Однако очевидно мы видим что в нашей выборке существуют эмпирические отклонения. 

Первое что научимся делать --- подсчитывать на сколько значимым является это отклонение

![Проверка гипотезы о распределении номинативной переменной](img/stat1.PNG)

### Проверка гипотезы о взаимосвязи двух номинативных переменных

Дaнные о том, подействовало ли лекарство на больного

![Проверка гипотезы о взаимосвязи двух номинативных переменных](img/stat2.PNG)

Обе переменные номинативные --- лекарство а, лекарство б. Поправился или не поправился

### Более сложные модели

Хотим предсказать, как влияют другие переменные на выздаровление.

Зависимая переменная нашего анализа будет являться номинативная переменная с двумя градациями. Такой тип регрессии называется логистическая регрессия.

## Расстояние Пирсона

Поговорим о том, как проверять гипотезу о различаях некоторого наблюдаемого распределения и предсказанного теоретического.

В случае номинативных данных основным показателем является подсчёт частоты встречаемости признака.

Гипотеза о том что некоторое наблюдаемое эмперическое распределение частот отличается от теоретического.
Для этого пойдём знакомым путём --- проверим п-уровень значимости. 
Зафиксируем насколько сильно отклоняется предсказанное от теоретического.

Для начала проверим гипотезу о том, что орёл и решка выпадает равновероятно.

### Подброс монетки

Результат бросания монетки это --- номинативная переменная орёл или решка.
Подбрасываем 60 раз. Предположим орёл выпал 40 раз, решка 20.

Нулевая гипотеза: распределение орла и решки равновероятна.

Альтернативная гипотеза: распределение орла отлично от распределения решки. Иными словами

$$H_0: p_{орла} = 0.5$$
$$H_1: p_{орла} \neq 0.5$$

Первое что мы должны сделать --- проверить на сколько отклоняются предсказанные от полученных.

Наблюдаемые обозначим буквой O (англ. Observe). Предсказанные E (Expected).


|              | Орёл | Решка| 
| --------     |:----:|:----:|
| Observe (O)  | $40$ | $20$ |
| Expected (E) | $30$ | $30$ |

Итак как работает статистика --- она говорит, окей есть нулевая гипотеза, есть ожидаемые резуьтаты, есть эмпирические данные. Смотрим есть ли расхождения. Нужно получить некое численное значение.

Далее мы говорим: а если бы нулевая гипотеза была верна, и мы много раз повторяли эксперимент, то как бы вела некая интересующая нас статистика.

Первое что приходит на ум: смотреть разность ожидаемых и наблюдаемых.

$$d = (O_1-E_1) + (O_2-E_2) = (40-30) + (20-30) = 0$$

Это не самый лучший вариант, посколько в итоге мы получили что отклонений нет

Можно возвести в квадрат разности, чтобы избавиться от минуса.

$$d^2 = (O_1-E_1)^2 + (O_2-E_2)^2 = (40-30)^2 + (20-30)^2 = 200$$
Но такой вариант тоже плохой. Потому что в такой формуле получается, что одно и то же значение  $d^2$  может характеризовать как довольно значительные, так и практически несущественные расхождения между наблюдаемыми и ожидаемыми частотами. Если бы у нас была другая выборка:

|              | Орёл   | Решка  | 
| --------     |:------:|:------:|
| Observe (O)  | $1040$ | $1020$ |
| Expected (E) | $1030$ | $1030$ |

То мы получили бы точно такое же численное значение

$$d^2 = (O_1-E_1)^2 + (O_2-E_2)^2 = (1040-1030)^2 + (1020-1030)^2 = 200$$

Пирсон тоже понял что такой подход неправильный. И математически доказал, что корректна будет формула

$$X^2_{Pearson} = \sum_{i=1}^{k}\bigg(\frac{O_i-E_i}{\sqrt{E_i}}\bigg)^2$$
k --- это все наши ячейки. Из этой формулы следует два простых вывода:

* Расстояние хи-квадрат Пирсона может равняться нулю.

* Расстояние хи-квадрат не может быть отрицательным.

Или в нашем случае это будет

$$X^2_{Pearson} = \sum_{i=1}^{k}\bigg(\frac{O_i-E_i}{\sqrt{E_i}}\bigg)^2 = (\frac{(40-30)}{\sqrt{30}})^ 2 - (\frac{(20-30)}{\sqrt{30}})^2 = \frac{100}{30} + \frac{100}{30} \approx 6.7 $$

Теперь второй вопрос --- если верна нулевая гипотеза, как бы вёл себя этот показатель $\chi^2$ при многократном повторении. И для этого нам надо познакомиться с распределением $\chi^2$

### Пример

В одном из опытов эмпирическое распределение частот некоторого цвета гороха приняло следующий вид: $O = \{18,55,27\}$

Чему будут равны ожидаемые значения частот, если предполагаемое теоретическое распределение имеет следующий вид: 1:2:1

Решение: У нас есть суммарное количество появления разных признаков $18+55+27=100$.
Есть суммарное отношение ожидаемых частот $1+2+1=4$.
Получаем что одна часть ожидаемого признака равняется $25$. Значит ожидаемые значения частот равны $E = \{25,50,25\}$

### Пример 2

Рассчитаем для этого случая значение $\chi^2$

$$X^2_{Pearson} = (\frac{(18-25)}{\sqrt{25}})^2 + (\frac{(55-50)}{\sqrt{50}})^2 + (\frac{(27-25)}{\sqrt{25}})^2 = \frac{196+50+16}{100}=2.62$$