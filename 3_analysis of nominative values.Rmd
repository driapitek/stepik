---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Анализ номинативных данных

## Постановка задачи

Здесь будем рассматривать случаи, когда основной герой --- номинативная переменная


### Проверка гипотезы о распределении номинативной переменной

1. Хотим проверить гипотезу о том, что распределение некоторой номинативной переменной отличается от заданной.

Предположим, какая партия является фаворитом.

Гипотеза --- наше империческое распределение частот, отличается от заданного теоретического.

Нулевая гипотеза --- все три партии встречаются равновероятно. Однако очевидно мы видим что в нашей выборке существуют эмпирические отклонения. 

Первое что научимся делать --- подсчитывать на сколько значимым является это отклонение

![Проверка гипотезы о распределении номинативной переменной](img/stat1.PNG)

### Проверка гипотезы о взаимосвязи двух номинативных переменных

Дaнные о том, подействовало ли лекарство на больного

![Проверка гипотезы о взаимосвязи двух номинативных переменных](img/stat2.PNG)

Обе переменные номинативные --- лекарство а, лекарство б. Поправился или не поправился

### Более сложные модели

Хотим предсказать, как влияют другие переменные на выздаровление.

Зависимая переменная нашего анализа будет являться номинативная переменная с двумя градациями. Такой тип регрессии называется логистическая регрессия.

## Расстояние Пирсона

Поговорим о том, как проверять гипотезу о различаях некоторого наблюдаемого распределения и предсказанного теоретического.

В случае номинативных данных основным показателем является подсчёт частоты встречаемости признака.

Гипотеза о том что некоторое наблюдаемое эмперическое распределение частот отличается от теоретического.
Для этого пойдём знакомым путём --- проверим п-уровень значимости. 
Зафиксируем насколько сильно отклоняется предсказанное от теоретического.

Для начала проверим гипотезу о том, что орёл и решка выпадает равновероятно.

### Подброс монетки

Результат бросания монетки это --- номинативная переменная орёл или решка.
Подбрасываем 60 раз. Предположим орёл выпал 40 раз, решка 20.

Нулевая гипотеза: распределение орла и решки равновероятна.

Альтернативная гипотеза: распределение орла отлично от распределения решки. Иными словами

$$H_0: p_{орла} = 0.5$$
$$H_1: p_{орла} \neq 0.5$$

Первое что мы должны сделать --- проверить на сколько отклоняются предсказанные от полученных.

Наблюдаемые обозначим буквой O (англ. Observe). Предсказанные E (Expected).


|              | Орёл | Решка| 
| --------     |:----:|:----:|
| Observe (O)  | $40$ | $20$ |
| Expected (E) | $30$ | $30$ |

Итак как работает статистика --- она говорит, окей есть нулевая гипотеза, есть ожидаемые резуьтаты, есть эмпирические данные. Смотрим есть ли расхождения. Нужно получить некое численное значение.

Далее мы говорим: а если бы нулевая гипотеза была верна, и мы много раз повторяли эксперимент, то как бы вела некая интересующая нас статистика.

Первое что приходит на ум: смотреть разность ожидаемых и наблюдаемых.

$$d = (O_1-E_1) + (O_2-E_2) = (40-30) + (20-30) = 0$$

Это не самый лучший вариант, посколько в итоге мы получили что отклонений нет

Можно возвести в квадрат разности, чтобы избавиться от минуса.

$$d^2 = (O_1-E_1)^2 + (O_2-E_2)^2 = (40-30)^2 + (20-30)^2 = 200$$
Но такой вариант тоже плохой. Потому что в такой формуле получается, что одно и то же значение  $d^2$  может характеризовать как довольно значительные, так и практически несущественные расхождения между наблюдаемыми и ожидаемыми частотами. Если бы у нас была другая выборка:

|              | Орёл   | Решка  | 
| --------     |:------:|:------:|
| Observe (O)  | $1040$ | $1020$ |
| Expected (E) | $1030$ | $1030$ |

То мы получили бы точно такое же численное значение

$$d^2 = (O_1-E_1)^2 + (O_2-E_2)^2 = (1040-1030)^2 + (1020-1030)^2 = 200$$

Пирсон тоже понял что такой подход неправильный. И математически доказал, что корректна будет формула

$$X^2_{Pearson} = \sum_{i=1}^{k}\bigg(\frac{O_i-E_i}{\sqrt{E_i}}\bigg)^2$$
k --- это все наши ячейки. Из этой формулы следует два простых вывода:

* Расстояние хи-квадрат Пирсона может равняться нулю.

* Расстояние хи-квадрат не может быть отрицательным.

Или в нашем случае это будет

$$X^2_{Pearson} = \sum_{i=1}^{k}\bigg(\frac{O_i-E_i}{\sqrt{E_i}}\bigg)^2 = (\frac{(40-30)}{\sqrt{30}})^ 2 - (\frac{(20-30)}{\sqrt{30}})^2 = \frac{100}{30} + \frac{100}{30} \approx 6.7 $$

Теперь второй вопрос --- если верна нулевая гипотеза, как бы вёл себя этот показатель $\chi^2$ при многократном повторении. И для этого нам надо познакомиться с распределением $\chi^2$

### Пример

В одном из опытов эмпирическое распределение частот некоторого цвета гороха приняло следующий вид: $O = \{18,55,27\}$

Чему будут равны ожидаемые значения частот, если предполагаемое теоретическое распределение имеет следующий вид: 1:2:1

Решение: У нас есть суммарное количество появления разных признаков $18+55+27=100$.
Есть суммарное отношение ожидаемых частот $1+2+1=4$.
Получаем что одна часть ожидаемого признака равняется $25$. Значит ожидаемые значения частот равны $E = \{25,50,25\}$

### Пример 2

Рассчитаем для этого случая значение $\chi^2$

$$X^2_{Pearson} = (\frac{(18-25)}{\sqrt{25}})^2 + (\frac{(55-50)}{\sqrt{50}})^2 + (\frac{(27-25)}{\sqrt{25}})^2 = \frac{196+50+16}{100}=2.62$$

## Распределение Хи-квадрат Пирсона

Как будет выглядеть распределение?

Один из действенных подходов --- сделать симуляцию.

### Симуляция распределения

Итак что будем симулировать:

  1. 60 раз подбрасываем монетку. 
  
  2. Записываем сколько выпало орлов, а сколько решек.

  3. Ожидаем что выпадет 30 на 30.

  4. Считаем критерий хи-квадрат.
  
  5. Повторяем пункты 1-4 100 раз
  
100 раз повторяется эксперимент с подбрасыванием симметричной монетки 60 раз. 
Расстояние хи-квадрат рассчитывается для каждого эксперимента:

```{r}
chi_square_distance <- function() {
  e <- c(30, 30)
  sum((table(sample(x = 2, size = 60, replace = TRUE)) - e) ^ 2 / e)
}

results <- replicate(100, chi_square_distance())
hist(results)
```

Так замечательно, а теперь мы хотим знать --- какова вероятность получить такие или ещё более выраженные отклонения.

Если верна нулевая гипотеза --- то чаще всего отклонения между ожидаемым числом и наблюдаемым не будут большие. Сильные отклонения будут встречаться реже.

Это говорит, о том, что распределение будет нормальным

![Распределение Хи-квадрат](img/chi.png)

### Определение распределения Хи-квадрат

Мы вяснили --- если мы многократно повторяем эксперимент, и смотрим не сумма, а каждое слагаемое в отдельности.
То оказывается, что если верна нулевая гипотеза, то отклонения чаще всего не значительны и будут встречаться равновероятно как в одну так и в другую сторону.

Распределение Хи-квадрат с k-степенями свободы --- это распределение суммы квадратов k-независимых стандартных нормальных случайных величин.

Стандартное распределение --- нормальное распределение, где среднее равно нулю, а дисперсия единице.

Независимые --- это тот факт, что каждое последующее измерение не зависит от измерения предыдущего.

Для того чтобы понять откуда берётся каждое значение в распределении Хи-квадрат с двумя степенями свободы, давайте визуализируем весь процесс.

Предположим мы сделали программу, которая генерирует две стандартные случайные величины.

Вероятность получить значение хи-квадрат равное или большее 5.9 равняется 0.05. Это и есть критическое значение для 

![Распределение Хи-квадрат](img/chi1.png)

При достаточно большом количестве степеней свободы, распределение $\chi^2$ стремится к нормальному.

![Распределение Хи-квадрат](img/chi2.png)

## Расчёт p-уровня значимости

Итак, вспомним наши данные

|              | Орёл | Решка| 
| --------     |:----:|:----:|
| Observe (O)  | $40$ | $20$ |
| Expected (E) | $30$ | $30$ |

И распределение Хи-квадрат для этих данных.

$$X^2_{Pearson} = \bigg(\frac{O_1-E_1}{\sqrt{E_1}}\bigg)^2 + \bigg(\frac{O_2-E_2}{\sqrt{E_2}}\bigg)^2 $$

Если бы каждое из этих слогаемых было бы стандартным нормальным распределением в квадрате, то формула расстояния идеально бы описывалась нормальным распределением. 

Но эти измерения должны дыть независимы. Зная что выпало в первой ячейке, зная общее значение выпаших частот, зная ожидаемое распределение, мы всегда знаем чему равно второе слагаемое.

При этом нарушается требование независимости. Это является ярким подтверждением того, что получившееся распределение имеет только одну степень свободы

![Линейное распределение для значений степеней свободы df = 1](img/chi3.png)

Когда у нас несколько переменных (n = 4) и точное значение выборки(u) то при знании v1, v2,v3 мы сможем точно сказать v4.
v4 = u - (v1+v2+v3). То есть, нам не надо знать значение последней переменной n-1

Эта логика может быть обобщена для общего случая.

Итак, мы посморели чему равен критерий, теперь можно при помощи табличных данных установить чему будет равен p-уровень значимости.

![Линейное распределение для значений степеней свободы df = 1](img/chi4.png)

Табличные значения можно посмотреть на сайте.

![Линейное распределение для значений степеней свободы df = 1](img/chi5.png)

### Задача

Какой процент наблюдений лежит в диапазоне от 2 до 4 у распределения хи-квадрат с двумя степенями свободы?

[Калькулятор p-уровня значимости](https://gallery.shinyapps.io/dist_calc/)

Ответ: 

  * Для 4 --- P(X > 3.99) =
  
  * Для 2 --- P(X > 2) = 0.368
  
  Ответ: $$0.368 -  0.136 =  0.233$$

### Задача

Теперь рассчитаем p-уровень значимости для нашего примера с игральной костью. Напомню, что мы получили следующие значения наблюдаемых частот (от единички до шестерки):

10,10,10,5,10,15 

Проверьте нулевую гипотезу о том, что эмпирическое распределение частот не отличается от равномерного. В поле для ответа введите получившийся p-уровень значимости. 

[Калькулятор p-уровня значимости](https://gallery.shinyapps.io/dist_calc/)

Решение 
  * df = 5

  * O = $\{10,10,10,5,10,15\}$

  * E = $\{10,10,10,10,10,10\}$
  
$$\chi^2 = 4 \times \bigg(\frac{10-10}{\sqrt{10}}\bigg)^2 + \bigg(\frac{5-10}{\sqrt{10}}\bigg)^2 + \bigg(\frac{15-10}{\sqrt{10}}\bigg)^2 = 0 + \frac{25}{10} +\frac{25}{10} = 5$$

![Ответ](img/chi6.png)

### Задача

Вернемся к нашему примеру с политическими партиями! Проверьте гипотезу о том, что в ГС нет никаких различий в предпочтениях трех партий. Введите в поле для ответа получившееся значение статистики хи-квадрат с точностью хотя бы до одной цифры после запятой.

  * партия А = 10 голосов
  
  * партия Б = 30 г.
  
  * партия В = 50 г.

df = 2

Нулевая гипотеза --- распределение для всех партий одинаково. Т.е. если всего 90 голосов, то 

  * E = $\{30, 30, 30\}$

  * O = $\{10, 30, 50\}$
  
$$\chi^2 = \bigg(\frac{10-30}{\sqrt{30}}\bigg)^2 + 0 + \bigg(\frac{50-30}{\sqrt{30}}\bigg)^2 =\frac{80}{3} = 26.67$$

Проинтерпритиуем полученный рузельтат.

p < 0.05 --- отклоняем нулевую гипотезу.

Принимаем альтернативную гипотезу, что распределение предпочтений избирателей отличается от равномерного.
Отвергаем нулевую гипотезу о том, что число сторонников каждой из трех партий в генеральной совокупности одинаково.

```{r}
(0.53 * 1500) - 1500

45 * 45 * 2 / 750
```

### Задача

В 2013 году Эдвард Сноуден передал СМИ секретную информацию АНБ, касающуюся слежки американских спецслужб за информационными коммуникациями между гражданами. Однако его поступок вызвал неоднозначную реакцию в обществе. Исследовательский центр USA TODAY провел опрос 1500 граждан США с целью выяснить, воспринимают ли они поступок Сноудена как положительный или отрицательный. 53% опрошенных респондентов оценили разоблачение положительно.

При помощи теста хи-квадрат проверьте нулевую гипотезу о том, что в генеральной совокупности распределение отношения к поступку Сноудена является равномерным, то есть 50 на 50.

Решение

  * n = 1500
  
  * df = 1
  
  * E = $\{750; 750\}$

  * O = $ \{0.53 * 1500; 0.47 * 1500\} = \{795; 705\}$
  
  * Нулевая гипотеза --- в генеральной совокупности распределение отношения к поступку Сноудена является равномерным, то есть 50 на 50.
  
  * Альтернативная --- распределение отношения является не равномерным
  
  $$\chi^2 = \bigg(\frac{795-750}{\sqrt{750}}\bigg)^2 + 0 + \bigg(\frac{705-750}{\sqrt{750}}\bigg)^2 =\frac{4050}{750} = 5.4$$
  
  * $P(X > 5.4) = 0.0201$ --- отвергаем нулевую гипотезу, принимаем альтернативную.
  